{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5934ac3",
   "metadata": {},
   "source": [
    "# Train Baseline GAT Model\n",
    "\n",
    "This notebook trains a Graph Attention Network (GAT) for fraud detection on the transaction graph.\n",
    "\n",
    "## Overview\n",
    "1. Import libraries and load graph\n",
    "2. Create train/validation/test splits\n",
    "3. Initialize GAT model\n",
    "4. Define training functions\n",
    "5. Train with early stopping\n",
    "6. Evaluate and save results\n",
    "\n",
    "**Estimated time:** 10-20 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e4ac9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Always add project root to sys.path for src imports (Jupyter-safe)\n",
    "project_root = str(Path().resolve().parent)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.models import GAT\n",
    "from src.config import MODEL_CONFIG, TRAINING_CONFIG, ARTIFACTS_DIR, ARTIFACT_FILES\n",
    "from src.utils import set_random_seeds, get_device\n",
    "\n",
    "# Set random seeds\n",
    "set_random_seeds(TRAINING_CONFIG['random_seed'])\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507c0ded",
   "metadata": {},
   "source": [
    "## 1. Import Libraries & Setup\n",
    "\n",
    "Import required packages and initialize device and random seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5050a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[203769, 182], edge_index=[2, 672479], y=[203769], timestep=[203769], labeled_mask=[203769], unlabeled_mask=[203769])\n",
      "Train: 27938, Val: 9313, Test: 9313\n"
     ]
    }
   ],
   "source": [
    "graph_path = ARTIFACTS_DIR / ARTIFACT_FILES['baseline_graph']\n",
    "data = torch.load(graph_path, weights_only=False).to(device)\n",
    "print(data)\n",
    "\n",
    "# Get labeled indices\n",
    "labeled_indices = torch.where(data.labeled_mask)[0].cpu().numpy()\n",
    "labeled_y = data.y[data.labeled_mask].cpu().numpy()\n",
    "\n",
    "# Split using config values\n",
    "train_val_idx, test_idx = train_test_split(\n",
    "    labeled_indices, \n",
    "    test_size=TRAINING_CONFIG['train_test_split'], \n",
    "    random_state=TRAINING_CONFIG['random_seed'], \n",
    "    stratify=labeled_y\n",
    ")\n",
    "\n",
    "train_val_y = data.y[train_val_idx].cpu().numpy()\n",
    "train_idx, val_idx = train_test_split(\n",
    "    train_val_idx, \n",
    "    test_size=TRAINING_CONFIG['train_val_split'], \n",
    "    random_state=TRAINING_CONFIG['random_seed'], \n",
    "    stratify=train_val_y\n",
    ")\n",
    "\n",
    "# Create masks\n",
    "train_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "val_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "test_mask = torch.zeros(data.num_nodes, dtype=torch.bool, device=device)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "data.train_mask = train_mask\n",
    "data.val_mask = val_mask\n",
    "data.test_mask = test_mask\n",
    "\n",
    "print(f\"Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71569f8c",
   "metadata": {},
   "source": [
    "## 2. Load Graph & Create Data Splits\n",
    "\n",
    "Load the saved graph and create stratified train/validation/test splits.\n",
    "Only labeled nodes are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a986a145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 47,878\n"
     ]
    }
   ],
   "source": [
    "model = GAT(\n",
    "    in_channels=data.num_node_features,\n",
    "    hidden_channels=MODEL_CONFIG['hidden_channels'],\n",
    "    out_channels=MODEL_CONFIG['out_channels'],\n",
    "    num_heads=MODEL_CONFIG['num_heads'],\n",
    "    num_layers=MODEL_CONFIG['num_layers'],\n",
    "    dropout=MODEL_CONFIG['dropout']\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr=TRAINING_CONFIG['learning_rate'], \n",
    "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d4c669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16405 NaN values in features\n",
      "NaN values replaced with 0\n",
      "Feature stats - Min: -13.0934, Max: 445268.0000, Mean: 4.6095\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in features and handle them\n",
    "nan_mask = torch.isnan(data.x)\n",
    "if nan_mask.any():\n",
    "    print(f\"Found {nan_mask.sum().item()} NaN values in features\")\n",
    "    # Replace NaN with 0\n",
    "    data.x = torch.where(nan_mask, torch.zeros_like(data.x), data.x)\n",
    "    print(\"NaN values replaced with 0\")\n",
    "else:\n",
    "    print(\"No NaN values found in features\")\n",
    "\n",
    "# Check for inf values\n",
    "inf_mask = torch.isinf(data.x)\n",
    "if inf_mask.any():\n",
    "    print(f\"Found {inf_mask.sum().item()} inf values in features\")\n",
    "    # Replace inf with 0\n",
    "    data.x = torch.where(inf_mask, torch.zeros_like(data.x), data.x)\n",
    "    print(\"Inf values replaced with 0\")\n",
    "\n",
    "print(f\"Feature stats - Min: {data.x.min():.4f}, Max: {data.x.max():.4f}, Mean: {data.x.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116ba2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features normalized - Min: -12.8573, Max: 10486.3457, Mean: -0.0565\n"
     ]
    }
   ],
   "source": [
    "# Normalize features using standardization (mean=0, std=1) on training set\n",
    "train_x = data.x[data.train_mask]\n",
    "mean = train_x.mean(dim=0, keepdim=True)\n",
    "std = train_x.std(dim=0, keepdim=True)\n",
    "std = torch.where(std == 0, torch.ones_like(std), std)  # Avoid division by zero\n",
    "\n",
    "data.x = (data.x - mean) / std\n",
    "print(f\"Features normalized - Min: {data.x.min():.4f}, Max: {data.x.max():.4f}, Mean: {data.x.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aed516f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features clipped - Min: -10.0000, Max: 10.0000, Mean: -0.0682\n"
     ]
    }
   ],
   "source": [
    "# Clip extreme values to prevent gradient issues\n",
    "data.x = torch.clamp(data.x, min=-10, max=10)\n",
    "print(f\"Features clipped - Min: {data.x.min():.4f}, Max: {data.x.max():.4f}, Mean: {data.x.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6482a6d",
   "metadata": {},
   "source": [
    "## 3. Initialize GAT Model\n",
    "\n",
    "Create the Graph Attention Network with configuration from `src/config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc2fbf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions ready\n"
     ]
    }
   ],
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(mask):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out[mask].argmax(dim=1)\n",
    "    prob = F.softmax(out[mask], dim=1)[:, 1]\n",
    "    \n",
    "    y_true = data.y[mask].cpu().numpy()\n",
    "    y_pred = pred.cpu().numpy()\n",
    "    y_prob = prob.cpu().numpy()\n",
    "    \n",
    "    # Check for NaN values and handle them\n",
    "    if np.isnan(y_prob).any():\n",
    "        # Replace NaN with 0.5 (neutral probability)\n",
    "        y_prob = np.nan_to_num(y_prob, nan=0.5)\n",
    "    \n",
    "    # Only compute ROC AUC if we have both classes\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_prob)\n",
    "    except (ValueError, RuntimeError):\n",
    "        roc_auc = 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "print(\"Training functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d74428",
   "metadata": {},
   "source": [
    "## 4. Define Training & Evaluation Functions\n",
    "\n",
    "Set up functions for training epochs and computing evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70eeccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  10 | Loss: 0.3320 | Val F1: 0.1689 | Val AUC: 0.8313\n",
      "Epoch  20 | Loss: 0.2668 | Val F1: 0.4790 | Val AUC: 0.9014\n",
      "Epoch  30 | Loss: 0.2403 | Val F1: 0.5807 | Val AUC: 0.9216\n",
      "Epoch  40 | Loss: 0.2261 | Val F1: 0.6159 | Val AUC: 0.9367\n",
      "Epoch  50 | Loss: 0.2124 | Val F1: 0.6750 | Val AUC: 0.9444\n",
      "Epoch  60 | Loss: 0.2044 | Val F1: 0.6965 | Val AUC: 0.9493\n",
      "Epoch  70 | Loss: 0.1956 | Val F1: 0.7169 | Val AUC: 0.9522\n",
      "Epoch  80 | Loss: 0.1928 | Val F1: 0.7249 | Val AUC: 0.9550\n",
      "Epoch  90 | Loss: 0.1874 | Val F1: 0.7337 | Val AUC: 0.9578\n",
      "Epoch 100 | Loss: 0.1823 | Val F1: 0.7381 | Val AUC: 0.9602\n",
      "Epoch 110 | Loss: 0.1785 | Val F1: 0.7558 | Val AUC: 0.9617\n",
      "Epoch 120 | Loss: 0.1780 | Val F1: 0.7619 | Val AUC: 0.9633\n",
      "Epoch 130 | Loss: 0.1727 | Val F1: 0.7656 | Val AUC: 0.9652\n",
      "Epoch 140 | Loss: 0.1705 | Val F1: 0.7729 | Val AUC: 0.9667\n",
      "Epoch 150 | Loss: 0.1682 | Val F1: 0.7734 | Val AUC: 0.9682\n",
      "Epoch 160 | Loss: 0.1645 | Val F1: 0.7795 | Val AUC: 0.9693\n",
      "Epoch 170 | Loss: 0.1629 | Val F1: 0.7886 | Val AUC: 0.9702\n"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'val_metrics': []}\n",
    "best_val_f1 = 0\n",
    "patience_counter = 0\n",
    "EPOCHS = TRAINING_CONFIG['epochs']\n",
    "PATIENCE = TRAINING_CONFIG['patience']\n",
    "\n",
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = train_epoch()\n",
    "    val_metrics = evaluate(data.val_mask)\n",
    "    \n",
    "    history['train_loss'].append(loss)\n",
    "    history['val_metrics'].append(val_metrics)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch:3d} | Loss: {loss:.4f} | Val F1: {val_metrics['f1']:.4f} | \"\n",
    "              f\"Val AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    if val_metrics['f1'] > best_val_f1:\n",
    "        best_val_f1 = val_metrics['f1']\n",
    "        patience_counter = 0\n",
    "        save_path = ARTIFACTS_DIR / ARTIFACT_FILES['baseline_model']\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'val_f1': best_val_f1,\n",
    "            'val_metrics': val_metrics\n",
    "        }, save_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training done in {training_time:.2f}s. Best Val F1: {best_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf41256",
   "metadata": {},
   "source": [
    "## 5. Train Model with Early Stopping\n",
    "\n",
    "Train the model for up to 200 epochs with early stopping based on validation F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "571198d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline GAT Results:\n",
      "Train - F1: 0.8105, AUC: 0.9750\n",
      "Val   - F1: 0.7886, AUC: 0.9702\n",
      "Test  - F1: 0.7938, AUC: 0.9698\n"
     ]
    }
   ],
   "source": [
    "model_path = ARTIFACTS_DIR / ARTIFACT_FILES['baseline_model']\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "train_metrics = evaluate(data.train_mask)\n",
    "val_metrics = evaluate(data.val_mask)\n",
    "test_metrics = evaluate(data.test_mask)\n",
    "\n",
    "print(\"\\nBaseline GAT Results:\")\n",
    "print(f\"Train - F1: {train_metrics['f1']:.4f}, AUC: {train_metrics['roc_auc']:.4f}\")\n",
    "print(f\"Val   - F1: {val_metrics['f1']:.4f}, AUC: {val_metrics['roc_auc']:.4f}\")\n",
    "print(f\"Test  - F1: {test_metrics['f1']:.4f}, AUC: {test_metrics['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11c34d",
   "metadata": {},
   "source": [
    "## 6. Load Best Model & Evaluate\n",
    "\n",
    "Load the best checkpoint and evaluate on train/val/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c819b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics saved to c:\\Users\\tusha\\Documents\\UT_Dallas\\ACM_SP26\\imple2\\artifacts\\gat_baseline_metrics.json\n",
      "Proceed to 04_eval_baseline.ipynb\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = {\n",
    "    'model_type': 'GAT_Baseline',\n",
    "    'training_time': training_time,\n",
    "    'best_epoch': checkpoint['epoch'],\n",
    "    'performance': {\n",
    "        'train': train_metrics,\n",
    "        'val': val_metrics,\n",
    "        'test': test_metrics\n",
    "    }\n",
    "}\n",
    "\n",
    "metrics_path = ARTIFACTS_DIR / ARTIFACT_FILES['baseline_metrics']\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\nMetrics saved to {metrics_path}\")\n",
    "print(\"Proceed to 04_eval_baseline.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0b15f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Baseline Training Complete!\n",
    "\n",
    "Model saved to `artifacts/gat_baseline.pt`. Proceed to **04_eval_baseline.ipynb** for detailed evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9cc05",
   "metadata": {},
   "source": [
    "## 7. Save Metrics to JSON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
