{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1df4a17",
   "metadata": {},
   "source": [
    "# Data Graph Construction\n",
    "\n",
    "Construct the Bitcoin transaction graph from raw data.\n",
    "\n",
    "**Steps:**\n",
    "1. Load node features from CSV\n",
    "2. Load node labels (fraud/non-fraud)\n",
    "3. Load edge list (transactions)\n",
    "4. Create PyTorch Geometric Data object\n",
    "5. Save to artifacts for training\n",
    "\n",
    "**Data:** Elliptic++ Bitcoin Dataset\n",
    "- ~203k nodes (Bitcoin addresses)\n",
    "- ~230k edges (transactions)\n",
    "- 181 features per node (temporal + structural)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c14569",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c4bb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.config import DATASET_CONFIG, TRAINING_CONFIG, DATA_DIR, ARTIFACTS_DIR, FIGURES_DIR\n",
    "from src.utils import set_random_seeds\n",
    "\n",
    "# Set random seeds\n",
    "set_random_seeds(TRAINING_CONFIG['random_seed'])\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64718d0a",
   "metadata": {},
   "source": [
    "### What This Cell Does\n",
    "This cell imports all necessary libraries and sets up the environment:\n",
    "- **os, sys, Path**: File system operations\n",
    "- **pandas**: Reading CSV files\n",
    "- **numpy**: Numerical operations\n",
    "- **torch**: PyTorch framework (neural networks)\n",
    "- **torch_geometric**: Graph neural network library\n",
    "- **matplotlib**: Visualization\n",
    "- **tqdm**: Progress bars\n",
    "\n",
    "Then it:\n",
    "1. Sets environment variable for GPU compatibility\n",
    "2. Adds project root to Python path (so we can import `src/`)\n",
    "3. Loads configuration from `src/config.py`\n",
    "4. Sets random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c616b02",
   "metadata": {},
   "source": [
    "## Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4312be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading features...\")\n",
    "features_file = DATA_DIR / DATASET_CONFIG['features_file']\n",
    "df_features = pd.read_csv(features_file, header=0)\n",
    "print(f\"Shape: {df_features.shape}\")\n",
    "\n",
    "node_ids = df_features.iloc[:, 0].values\n",
    "timesteps = df_features.iloc[:, 1].values\n",
    "features = df_features.iloc[:, 2:].values.astype(np.float32)\n",
    "\n",
    "node_id_to_idx = {nid: idx for idx, nid in enumerate(node_ids)}\n",
    "print(f\"Nodes: {len(node_ids):,}, Features: {features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9248a",
   "metadata": {},
   "source": [
    "### What This Cell Does (Load Features)\n",
    "This cell loads the **node features** (182 numbers per Bitcoin address):\n",
    "\n",
    "1. **Read CSV file**: `txs_features.csv` contains:\n",
    "   - Column 0: node_id (unique address identifier)\n",
    "   - Column 1: timestep (time period)\n",
    "   - Columns 2-183: 182 numerical features\n",
    "\n",
    "2. **Extract components**:\n",
    "   - `node_ids`: Address identifiers (needed for mapping)\n",
    "   - `timesteps`: Time information\n",
    "   - `features`: The 182 numerical values per node\n",
    "\n",
    "3. **Create mapping**: `node_id_to_idx` is a dictionary:\n",
    "   - Key: original node ID from CSV\n",
    "   - Value: index 0-203k (needed for edges later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1160cee8",
   "metadata": {},
   "source": [
    "## Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb22c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading labels...\")\n",
    "classes_file = DATA_DIR / DATASET_CONFIG['classes_file']\n",
    "df_classes = pd.read_csv(classes_file)\n",
    "print(\"Original class distribution:\")\n",
    "print(df_classes[DATASET_CONFIG['label_column']].value_counts())\n",
    "\n",
    "labels = np.full(len(node_ids), -1, dtype=np.int64)\n",
    "\n",
    "illicit_label = DATASET_CONFIG['illicit_label']\n",
    "licit_label = DATASET_CONFIG['licit_label']\n",
    "\n",
    "for _, row in tqdm(df_classes.iterrows(), total=len(df_classes), desc=\"Processing labels\"):\n",
    "    node_id = row[DATASET_CONFIG['id_column']]\n",
    "    if node_id in node_id_to_idx:\n",
    "        idx = node_id_to_idx[node_id]\n",
    "        if row[DATASET_CONFIG['label_column']] == illicit_label:\n",
    "            labels[idx] = 1  # Illicit\n",
    "        elif row[DATASET_CONFIG['label_column']] == licit_label:\n",
    "            labels[idx] = 0  # Licit\n",
    "        # Unknown (3) remains -1\n",
    "\n",
    "labeled_mask = labels != -1\n",
    "print(f\"\\nLabeled: {labeled_mask.sum():,}, Unlabeled: {(~labeled_mask).sum():,}\")\n",
    "print(f\"Licit (0): {(labels==0).sum():,}, Illicit (1): {(labels==1).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43662457",
   "metadata": {},
   "source": [
    "### What This Cell Does (Load Labels)\n",
    "This cell loads the **classification labels** (whether each address is illicit or licit):\n",
    "\n",
    "1. **Read CSV file**: `txs_classes.csv` contains:\n",
    "   - Column: node_id (address identifier)\n",
    "   - Column: class (0=licit, 1=illicit, 3=unknown)\n",
    "\n",
    "2. **Initialize label array**: Create array of size 203k with -1 (unlabeled):\n",
    "   - Initialize all nodes as unknown/unlabeled initially\n",
    "   - Then fill in known labels\n",
    "\n",
    "3. **Map labels to indices**: For each node in classes file:\n",
    "   - Find its index using `node_id_to_idx` dictionary\n",
    "   - Set label[index] = 0 (licit) or 1 (illicit)\n",
    "   - Unknown nodes (3) remain -1 for semi-supervised learning\n",
    "\n",
    "4. **Calculate statistics**: \n",
    "   - Count how many nodes have labels vs don't\n",
    "   - Show class balance (how many illicit vs licit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a3adf",
   "metadata": {},
   "source": [
    "## Load Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42454aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading edges...\")\n",
    "edgelist_file = DATA_DIR / DATASET_CONFIG['edgelist_file']\n",
    "df_edges = pd.read_csv(edgelist_file)\n",
    "print(f\"Edges in file: {len(df_edges):,}\")\n",
    "\n",
    "edge_list = []\n",
    "for _, row in tqdm(df_edges.iterrows(), total=len(df_edges), desc=\"Processing edges\"):\n",
    "    src_id = row[DATASET_CONFIG['edge_source_column']]\n",
    "    dst_id = row[DATASET_CONFIG['edge_target_column']]\n",
    "    \n",
    "    if src_id in node_id_to_idx and dst_id in node_id_to_idx:\n",
    "        src_idx = node_id_to_idx[src_id]\n",
    "        dst_idx = node_id_to_idx[dst_id]\n",
    "        edge_list.append([src_idx, dst_idx])\n",
    "        edge_list.append([dst_idx, src_idx])  # Make undirected\n",
    "\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "print(f\"Edge index shape (before self-loops): {edge_index.shape}\")\n",
    "\n",
    "# Add self-loops for GAT\n",
    "edge_index, _ = add_self_loops(edge_index, num_nodes=len(node_ids))\n",
    "print(f\"Edge index shape (after self-loops): {edge_index.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210d053",
   "metadata": {},
   "source": [
    "### What This Cell Does (Load Edges)\n",
    "This cell loads the **transaction edges** that connect addresses:\n",
    "\n",
    "1. **Read CSV file**: `txs_edgelist.csv` contains:\n",
    "   - Column: source_id (from address)\n",
    "   - Column: target_id (to address) \n",
    "   - Each row is ONE transaction direction\n",
    "\n",
    "2. **Map edges to indices**:\n",
    "   - For each edge (source → target):\n",
    "   - Look up source_id in `node_id_to_idx` to get source index\n",
    "   - Look up target_id in `node_id_to_idx` to get target index\n",
    "   - Keep only edges between nodes we have features for (skip if not in node_id_to_idx)\n",
    "\n",
    "3. **Make graph undirected**:\n",
    "   - Add reverse edge (target → source) for each original edge\n",
    "   - This means each transaction becomes TWO edges (bidirectional)\n",
    "   - Graph Attention works better with undirected edges for Bitcoin data\n",
    "\n",
    "4. **Add self-loops**:\n",
    "   - For graph neural networks, add edges where source = target\n",
    "   - Helps model learn node's own feature importance alongside neighbors\n",
    "\n",
    "5. **Create edge_index tensor**:\n",
    "   - Stack all edges into [2, num_edges] tensor\n",
    "   - First row: source indices\n",
    "   - Second row: target indices\n",
    "   - This is PyTorch Geometric edge representation format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f632970f",
   "metadata": {},
   "source": [
    "## Create PyTorch Geometric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8edf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(features, dtype=torch.float32)\n",
    "y = torch.tensor(labels, dtype=torch.long)\n",
    "timestep_tensor = torch.tensor(timesteps, dtype=torch.long)\n",
    "labeled_mask_tensor = torch.tensor(labeled_mask, dtype=torch.bool)\n",
    "unlabeled_mask_tensor = torch.tensor(~labeled_mask, dtype=torch.bool)\n",
    "\n",
    "data = Data(\n",
    "    x=x,\n",
    "    edge_index=edge_index,\n",
    "    y=y,\n",
    "    timestep=timestep_tensor,\n",
    "    labeled_mask=labeled_mask_tensor,\n",
    "    unlabeled_mask=unlabeled_mask_tensor\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(data)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0f8d3",
   "metadata": {},
   "source": [
    "### What This Cell Does (Create PyTorch Geometric Data)\n",
    "This cell packages all the loaded data into a **PyTorch Geometric Data object**:\n",
    "\n",
    "1. **Convert to PyTorch tensors**:\n",
    "   - `x`: Node features (203k × 182) - the 182 numerical values per address\n",
    "   - `y`: Labels (203k,) - 0 for licit, 1 for illicit, -1 for unlabeled\n",
    "   - `timestep`: Time period for each node (for temporal analysis)\n",
    "   - `labeled_mask`: Boolean array showing which nodes have labels\n",
    "   - `unlabeled_mask`: Boolean array showing which nodes don't have labels\n",
    "\n",
    "2. **Create Data object**:\n",
    "   - Combines all the above into ONE object\n",
    "   - `edge_index`: The transaction graph connectivity\n",
    "   - PyTorch Geometric models expect this format\n",
    "   - This is the standard way to represent graphs in deep learning\n",
    "\n",
    "3. **Why this matters**:\n",
    "   - The Data object is what gets passed to neural network models\n",
    "   - Models expect: node features (x), edges (edge_index), labels (y)\n",
    "   - The masks let the model know which nodes to use for training vs evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34478651",
   "metadata": {},
   "source": [
    "## Save Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories if needed\n",
    "ARTIFACTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save graph\n",
    "save_path = ARTIFACTS_DIR / 'elliptic_graph.pt'\n",
    "torch.save(data, save_path)\n",
    "print(f\"✓ Graph saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5876cb31",
   "metadata": {},
   "source": [
    "### What This Cell Does (Save Graph)\n",
    "This cell saves the constructed graph to disk for **reuse in later training**:\n",
    "\n",
    "1. **Create directories**:\n",
    "   - Ensure `artifacts/` folder exists (where models and data are saved)\n",
    "   - Ensure `figures/` folder exists (where visualizations go)\n",
    "\n",
    "2. **Save as PyTorch checkpoint**:\n",
    "   - Save the entire Data object to `elliptic_graph.pt`\n",
    "   - Uses pickle format (PyTorch's standard `torch.save()`)\n",
    "   - File size: ~200MB (includes all features, edges, labels)\n",
    "\n",
    "3. **Why save instead of rebuild**:\n",
    "   - Graph creation takes 5-10 minutes (reading CSVs, mapping nodes, processing edges)\n",
    "   - Saving allows later notebooks to load in milliseconds\n",
    "   - Consistency: Everyone uses the exact same graph (no random variations)\n",
    "   - `sanity_checks.ipynb` and training notebooks will load and reuse this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a5d42",
   "metadata": {},
   "source": [
    "## Visualize Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781e4f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Labels\n",
    "label_counts = [(labels==0).sum(), (labels==1).sum(), (~labeled_mask).sum()]\n",
    "axes[0].bar(['Licit', 'Illicit', 'Unknown'], label_counts, color=['green', 'red', 'gray'])\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Label Distribution')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Timesteps\n",
    "axes[1].hist(timesteps, bins=50, edgecolor='black')\n",
    "axes[1].set_xlabel('Timestep')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('Temporal Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = FIGURES_DIR / 'data_distribution.png'\n",
    "plt.savefig(save_path, dpi=150)\n",
    "print(f\"✓ Figure saved to {save_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc789918",
   "metadata": {},
   "source": [
    "### What This Cell Does (Visualize Data Distribution)\n",
    "This cell creates visualizations to understand the **dataset composition**:\n",
    "\n",
    "1. **Left plot - Label distribution** (logged scale):\n",
    "   - Shows how many licit addresses (green)\n",
    "   - Shows how many illicit addresses (red) \n",
    "   - Shows how many unlabeled/unknown addresses (gray)\n",
    "   - Logged scale because unlabeled count is much larger\n",
    "   - Reveals class imbalance: far fewer illicit than licit addresses\n",
    "\n",
    "2. **Right plot - Temporal distribution**:\n",
    "   - Histogram of timesteps (time periods)\n",
    "   - Shows which time periods have most transactions\n",
    "   - Important for understanding if data is evenly distributed in time\n",
    "   - Helps verify dataset covers multiple time periods\n",
    "\n",
    "3. **Save figure**:\n",
    "   - Saves both plots to `figures/data_distribution.png`\n",
    "   - Good for reports, presentations, documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e620bc9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ GRAPH CONSTRUCTION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run 01_baseline_gat_training.ipynb for baseline model\")\n",
    "print(\"2. Run 02_quantum_gat_training.ipynb for quantum model\")\n",
    "print(\"3. Run 03_data_sanity_checks.ipynb for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7e73a",
   "metadata": {},
   "source": [
    "### What This Cell Does (Summary)\n",
    "This cell provides a **completion summary and next steps**:\n",
    "\n",
    "1. **Marks completion**:\n",
    "   - Prints success message indicating graph is ready\n",
    "   - Confirms that `elliptic_graph.pt` has been saved\n",
    "\n",
    "2. **Tells what to do next**:\n",
    "   - Run `sanity_checks.ipynb` to verify graph structure\n",
    "   - Run `baseline_gat_training.ipynb` to train the baseline model\n",
    "   - Run `quantum_gat_training.ipynb` to train the quantum model\n",
    "\n",
    "3. **Workflow progression**:\n",
    "   - This notebook (create_graph): Build the graph → ✓ DONE\n",
    "   - Next: Verify it's correct (sanity_checks)\n",
    "   - Then: Train models using this graph"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
