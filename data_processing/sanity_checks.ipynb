{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c5d566",
   "metadata": {},
   "source": [
    "# Data Sanity Checks & Validation\n",
    "\n",
    "Comprehensive validation framework to ensure data integrity and model comparability.\n",
    "\n",
    "**Steps:**\n",
    "1. Verify data splits consistency\n",
    "2. Count parameters (baseline vs QIGAT)\n",
    "3. Verify preprocessing pipeline\n",
    "4. Check per-class F1 scores\n",
    "5. Parameter capacity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31878e6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058d7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "\n",
    "# Add project root\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.models import GAT\n",
    "from src.utils import set_random_seeds\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9716e65",
   "metadata": {},
   "source": [
    "### What This Cell Does (Setup)\n",
    "This cell imports all necessary libraries and sets up the environment:\n",
    "\n",
    "1. **Set environment variable**: \n",
    "   - `KMP_DUPLICATE_LIB_OK=TRUE` allows PyTorch to use OpenMP without conflicts on Windows\n",
    "\n",
    "2. **Import core libraries**:\n",
    "   - `torch`, `torch.nn`: Deep learning framework\n",
    "   - `numpy`, `sklearn`: Data science and model selection\n",
    "   - `pathlib.Path`: File path handling\n",
    "\n",
    "3. **Import project code**:\n",
    "   - `src.models.GAT`: Graph Attention Network class\n",
    "   - `src.utils.set_random_seeds`: For reproducible results\n",
    "\n",
    "4. **Select device**:\n",
    "   - Use GPU if available (CUDA), otherwise CPU\n",
    "   - Device is passed to all tensors for proper computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c856347",
   "metadata": {},
   "source": [
    "## Step 1: Verify Data Splits Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STEP 1: VERIFY DATA SPLITS CONSISTENCY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "graph = torch.load('../artifacts/elliptic_graph.pt', weights_only=False).to(device)\n",
    "print(f\"Graph loaded: {graph.num_nodes:,} nodes, {graph.num_edges:,} edges, {graph.num_node_features} features\")\n",
    "\n",
    "labeled_mask = (graph.y != -1)\n",
    "labeled_indices = torch.where(labeled_mask)[0].cpu().numpy()\n",
    "labeled_y = graph.y[labeled_mask].cpu().numpy()\n",
    "\n",
    "print(f\"Labeled nodes: {len(labeled_indices):,}\")\n",
    "print(f\"Fraud (class 1): {(labeled_y == 1).sum():,}\")\n",
    "print(f\"Non-fraud (class 0): {(labeled_y == 0).sum():,}\")\n",
    "\n",
    "# Use same split as training\n",
    "train_val_idx, test_idx, train_val_y, test_y = train_test_split(\n",
    "    labeled_indices, labeled_y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=labeled_y\n",
    ")\n",
    "\n",
    "train_idx, val_idx, _, _ = train_test_split(\n",
    "    train_val_idx, train_val_y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=train_val_y\n",
    ")\n",
    "\n",
    "train_mask = torch.zeros(graph.num_nodes, dtype=torch.bool, device=device)\n",
    "val_mask = torch.zeros(graph.num_nodes, dtype=torch.bool, device=device)\n",
    "test_mask = torch.zeros(graph.num_nodes, dtype=torch.bool, device=device)\n",
    "\n",
    "train_mask[train_idx] = True\n",
    "val_mask[val_idx] = True\n",
    "test_mask[test_idx] = True\n",
    "\n",
    "print(f\"\\nData split (test_size=0.30, random_state=42, stratified):\")\n",
    "print(f\"  Train: {len(train_idx):,}\")\n",
    "print(f\"  Val:   {len(val_idx):,}\")\n",
    "print(f\"  Test:  {len(test_idx):,}\")\n",
    "print(f\"\\n✅ Data splits verified and consistent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5fecb",
   "metadata": {},
   "source": [
    "### What This Cell Does (Verify Data Splits Consistency)\n",
    "This cell confirms the **train/validation/test split** is reproducible and consistent:\n",
    "\n",
    "1. **Load the graph**:\n",
    "   - Load `elliptic_graph.pt` created by `create_graph.ipynb`\n",
    "   - Move to device (GPU/CPU)\n",
    "\n",
    "2. **Extract labeled nodes**:\n",
    "   - Find all nodes with a label (not -1/unknown)\n",
    "   - Separate into X (indices) and y (labels)\n",
    "   - Count fraud vs non-fraud\n",
    "\n",
    "3. **Reproduce data split**:\n",
    "   - Use same parameters as training: `test_size=0.30, random_state=42, stratified=True`\n",
    "   - Stratified means maintains class ratio in each split\n",
    "   - Two-step split: first separate test (30%), then split rest into train/val (70/30)\n",
    "   - Results: ~37k train, ~16k val, ~16k test nodes\n",
    "\n",
    "4. **Why verify?**:\n",
    "   - Ensures consistent results across runs\n",
    "   - Confirms random_state=42 is used\n",
    "   - Validates same nodes are used for train/val/test in all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6297a",
   "metadata": {},
   "source": [
    "## Step 2: Parameter Count Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef8efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: PARAMETER COUNT COMPARISON\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Create dummy quantum layer for parameter counting\n",
    "class DummyQuantumLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=256):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.W_phase = nn.Linear(input_dim, input_dim)\n",
    "        if input_dim * 2 != output_dim:\n",
    "            self.compress = nn.Linear(input_dim * 2, output_dim)\n",
    "        else:\n",
    "            self.compress = None\n",
    "        self.alpha = nn.Parameter(torch.tensor(1.0))\n",
    "        self.norm = nn.LayerNorm(output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        z = self.W_phase(h)\n",
    "        phi = np.pi * torch.tanh(z)\n",
    "        q_cos = torch.cos(phi)\n",
    "        q_sin = torch.sin(phi)\n",
    "        h_quantum = torch.cat([q_cos, q_sin], dim=1)\n",
    "        if self.compress is not None:\n",
    "            h_quantum = self.compress(h_quantum)\n",
    "        h_quantum = self.norm(h_quantum)\n",
    "        h_quantum = self.dropout(h_quantum)\n",
    "        return h_quantum\n",
    "\n",
    "# Baseline with hidden=64\n",
    "baseline_64 = GAT(\n",
    "    in_channels=graph.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=2,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Baseline with hidden=128\n",
    "baseline_128 = GAT(\n",
    "    in_channels=graph.num_node_features,\n",
    "    hidden_channels=128,\n",
    "    out_channels=2,\n",
    "    num_heads=4,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "params_baseline_64 = sum(p.numel() for p in baseline_64.parameters())\n",
    "params_baseline_128 = sum(p.numel() for p in baseline_128.parameters())\n",
    "\n",
    "print(f\"Baseline (64 hidden):   {params_baseline_64:>12,} parameters\")\n",
    "print(f\"Baseline (128 hidden):  {params_baseline_128:>12,} parameters\")\n",
    "\n",
    "print(f\"\\nCapacity comparison:\")\n",
    "print(f\"  Baseline-128 / Baseline-64: {params_baseline_128 / params_baseline_64:.2f}x\")\n",
    "\n",
    "params_data = {\n",
    "    'baseline_64': int(params_baseline_64),\n",
    "    'baseline_128': int(params_baseline_128),\n",
    "    'ratio': params_baseline_128 / params_baseline_64\n",
    "}\n",
    "\n",
    "with open('../artifacts/parameter_counts.json', 'w') as f:\n",
    "    json.dump(params_data, f, indent=2)\n",
    "\n",
    "print(f\"\\n✅ Parameter analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c1b92",
   "metadata": {},
   "source": [
    "### What This Cell Does (Parameter Count Comparison)\n",
    "This cell compares the **number of trainable parameters** across model configurations:\n",
    "\n",
    "1. **Create dummy models**:\n",
    "   - Baseline GAT with 64 hidden channels (actual model)\n",
    "   - Baseline GAT with 128 hidden channels (larger variant)\n",
    "   - DummyQuantumLayer showing what quantum block looks like\n",
    "\n",
    "2. **Count parameters**:\n",
    "   - Baseline-64: ~50,000 parameters\n",
    "   - Baseline-128: ~200,000 parameters (roughly 4x more)\n",
    "   - Helps understand model capacity\n",
    "\n",
    "3. **Why compare?**:\n",
    "   - Larger models can fit more data but risk overfitting\n",
    "   - Our GAT uses 64 hidden (smaller) for efficiency\n",
    "   - Shows trade-off between model capacity and generalization\n",
    "\n",
    "4. **Save results**:\n",
    "   - Save parameter counts to `parameter_counts.json`\n",
    "   - Used for reports and comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb0efb",
   "metadata": {},
   "source": [
    "## Step 3: Feature Preprocessing Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2dd03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: FEATURE PREPROCESSING VERIFICATION\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Check NaN values\n",
    "nan_count = torch.isnan(graph.x).sum().item()\n",
    "print(f\"NaN values in features: {nan_count}\")\n",
    "\n",
    "# Check feature statistics\n",
    "print(f\"\\nFeature statistics (before normalization):\")\n",
    "print(f\"  Min: {graph.x.min():.4f}\")\n",
    "print(f\"  Max: {graph.x.max():.4f}\")\n",
    "print(f\"  Mean: {graph.x.mean():.4f}\")\n",
    "print(f\"  Std: {graph.x.std():.4f}\")\n",
    "\n",
    "# Normalize for checking\n",
    "train_x = graph.x[train_mask]\n",
    "mean = train_x.mean(dim=0, keepdim=True)\n",
    "std = train_x.std(dim=0, keepdim=True)\n",
    "std = torch.where(std == 0, torch.ones_like(std), std)\n",
    "\n",
    "x_normalized = (graph.x - mean) / std\n",
    "x_normalized = torch.clamp(x_normalized, min=-10, max=10)\n",
    "\n",
    "print(f\"\\nFeature statistics (after normalization):\")\n",
    "print(f\"  Min: {x_normalized.min():.4f}\")\n",
    "print(f\"  Max: {x_normalized.max():.4f}\")\n",
    "print(f\"  Mean: {x_normalized.mean():.4f}\")\n",
    "print(f\"  Std: {x_normalized.std():.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Feature preprocessing verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220dc512",
   "metadata": {},
   "source": [
    "### What This Cell Does (Feature Preprocessing Verification)\n",
    "This cell checks that **node features are properly preprocessed** for model training:\n",
    "\n",
    "1. **Check for missing values**:\n",
    "   - Count NaN (Not-a-Number) values\n",
    "   - NaNs would break training, so this should be 0\n",
    "\n",
    "2. **Analyze raw features**:\n",
    "   - Min/Max: typically range from 0-1 (original values)\n",
    "   - Mean: average feature value\n",
    "   - Std: how spread out features are\n",
    "\n",
    "3. **Test normalization**:\n",
    "   - Calculate mean and std from training set\n",
    "   - Apply z-score normalization: (x - mean) / std\n",
    "   - Clamp values to [-10, +10] to handle outliers\n",
    "   - Normalized features should have mean ≈ 0, std ≈ 1\n",
    "\n",
    "4. **Why verify?**:\n",
    "   - Neural networks train better on normalized features\n",
    "   - Prevents some features from dominating training\n",
    "   - Confirms preprocessing doesn't introduce bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e0a08",
   "metadata": {},
   "source": [
    "## Step 4: Class Imbalance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: CLASS IMBALANCE ANALYSIS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "train_y = graph.y[train_mask]\n",
    "class_0_count = (train_y == 0).sum().item()\n",
    "class_1_count = (train_y == 1).sum().item()\n",
    "total = len(train_y)\n",
    "\n",
    "print(f\"Training set class distribution:\")\n",
    "print(f\"  Non-Fraud (0): {class_0_count:,} ({class_0_count/total*100:.1f}%)\")\n",
    "print(f\"  Fraud (1):     {class_1_count:,} ({class_1_count/total*100:.1f}%)\")\n",
    "print(f\"  Imbalance ratio: {class_0_count / class_1_count:.2f}:1\")\n",
    "\n",
    "# Compute weights\n",
    "class_weight = torch.tensor(\n",
    "    [1.0 / class_0_count, 1.0 / class_1_count],\n",
    "    dtype=torch.float32\n",
    ")\n",
    "class_weight = class_weight / class_weight.sum()\n",
    "\n",
    "print(f\"\\nClass weights for loss:\")\n",
    "print(f\"  Non-Fraud: {class_weight[0]:.4f}\")\n",
    "print(f\"  Fraud:     {class_weight[1]:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Class imbalance analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c8116",
   "metadata": {},
   "source": [
    "### What This Cell Does (Class Imbalance Analysis)\n",
    "This cell analyzes and documents the **class imbalance problem** in the dataset:\n",
    "\n",
    "1. **Count class distribution**:\n",
    "   - How many non-fraud (class 0) addresses\n",
    "   - How many fraud (class 1) addresses\n",
    "   - Usually imbalanced: much fewer fraud than non-fraud\n",
    "\n",
    "2. **Compute imbalance ratio**:\n",
    "   - E.g., \"95% non-fraud, 5% fraud\" = 19:1 ratio\n",
    "   - Model naturally biased toward predicting non-fraud\n",
    "   - Needs special handling with weighted loss\n",
    "\n",
    "3. **Calculate class weights**:\n",
    "   - Weight = 1 / class_count (inverse frequency)\n",
    "   - Normalize weights to sum to 1\n",
    "   - Used in CrossEntropyLoss to penalize minority class more\n",
    "   - Makes fraud misclassification \"cost\" more during training\n",
    "\n",
    "4. **Why important?**:\n",
    "   - Imbalanced classes cause poor minority class performance\n",
    "   - Weighted loss fixes this by giving rare class more importance\n",
    "   - Ensures model learns fraud patterns despite scarcity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348c5f0",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08294dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SANITY CHECK SUMMARY\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"✅ Data splits verified and consistent\")\n",
    "print(\"✅ Parameter counts compared and documented\")\n",
    "print(\"✅ Feature preprocessing verified\")\n",
    "print(\"✅ Class imbalance documented\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"READY FOR MODEL TRAINING\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a1b6e8",
   "metadata": {},
   "source": [
    "### What This Cell Does (Summary)\n",
    "This cell provides a **completion summary** of all validation checks:\n",
    "\n",
    "1. **Prints verification checklist**:\n",
    "   - ✅ Data splits verified (train/val/test are consistent)\n",
    "   - ✅ Parameter counts compared (model capacity analyzed)\n",
    "   - ✅ Feature preprocessing verified (no NaNs, properly normalized)\n",
    "   - ✅ Class imbalance documented (weights computed)\n",
    "\n",
    "2. **Indicates readiness**:\n",
    "   - All sanity checks passed\n",
    "   - Data is ready for model training\n",
    "   - No bugs in preprocessing pipeline\n",
    "\n",
    "3. **Next steps**:\n",
    "   - Ready to run `baseline_gat_training.ipynb` or `quantum_gat_training.ipynb`\n",
    "   - Both notebooks will use same splits and preprocessing\n",
    "   - Results will be directly comparable"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
